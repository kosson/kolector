version: '2.4'
services:

  # nginx-proxy:
  #   image: jwilder/nginx-proxy
  #   ports:
  #     - "80:80"
  #   volumes:
  #     - /var/run/docker.sock:/tmp/docker.sock

  # nginx:
  #   image: nginx
  #   environment:
  #     - VIRTUAL_HOST=serviciul1.localhost

  # https://www.digitalocean.com/community/tutorials/containerizing-a-node-js-application-for-development-with-docker-compose
  infrastructura:
    build:
      context: .
      dockerfile: Dockerfile
      target: prod
    image: nodejs
    container_name: nodejs
    env_file: .env
    environment:
      - MONGO_USERNAME=$MONGO_USER
      - MONGO_PASSWORD=$MONGO_PASSWD
    ports:
      - '80:8080'
    volumes:
      - .:/var/www/kolector
    command: ./wait-for.sh db:27017 -- /home/node/app/node_modules/.bin/nodemon app.js
    depends_on: 
      servicenode:
        condition: service_healthy

  servicenode:
    image: node:14.4.0
    command: nodemon --inspect=0.0.0.0:9229 app.js
    environment: 
      - NODE_ENV=development
    ports:
      - '8080:80'
      - '9229:9229'
    healthcheck:
      # asigură-te că imaginea de node are curl preinstalat
      test: curl -f http://127.0.0.1
    depends_on:
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
      es01:
        condition: service_healthy
      es02:
        condition: service_healthy
      kibana:
        condition: service_healthy

  mongo:
    image: mongo:4.2.8-bionic
    env_file: .env
    environment:
      - MONGO_INITDB_ROOT_USERNAME=$MONGO_USER
      - MONGO_INITDB_ROOT_PASSWORD=$MONGO_PASSWD
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo localhost:27017/test --quiet
  
  redis:
      image: redis:alpine
      healthcheck:
        test: ["CMD", "redis-cli", "ping"]
        interval: 1s
        timeout: 3s
        retries: 30
  
  es01:
    image: elasticsearch:7.8.0
    container_name: es01
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Mărește la 2G: -Xmx2g -Xms2g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 3

  es02:
    image: elasticsearch:7.8.0
    container_name: es02
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 3
  # sudo nano /etc/sysctl.conf unde adaugi vm.max_map_count=262144
  # aplică setarea cu sysctl -w vm.max_map_count=262144
  kibana:
    image: kibana:7.8.0
    container_name: kibana
    depends_on:
      es01:
        condition: service_healthy
      es02:
        condition: service_healthy
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_URL=http://localhost:9200
      - XPACK_MONITORING_ENABLED=false

volumes:
  data01:
    driver: local
  data02:
    driver: local